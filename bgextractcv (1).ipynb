{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34880a1-fe87-488d-8412-90c93d5325de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('Videos/Captures/duck.mp4')\n",
    "\n",
    "# Background subtractor with adjusted parameters for less noise\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=150, varThreshold=20, detectShadows=False)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize the frame (50% of original size)\n",
    "    scale_percent = 50\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    frame_resized = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Apply a slight Gaussian blur to reduce noise in the input\n",
    "    frame_blurred = cv2.GaussianBlur(frame_resized, (5, 5), 0)\n",
    "    \n",
    "    # Apply background separation to detect motion\n",
    "    fgmask = fgbg.apply(frame_blurred)\n",
    "    \n",
    "   \n",
    "    # Convert to black and white (binary) for foreground\n",
    "    _, foreground_mask = cv2.threshold(fgmask, 125, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Foreground alone: Apply mask to original frame\n",
    "    foreground = cv2.bitwise_and(frame_resized, frame_resized, mask=foreground_mask)\n",
    "    \n",
    "    # Background alone: Invert the mask and apply to original frame\n",
    "    background_mask = cv2.bitwise_not(foreground_mask)\n",
    "    background = cv2.bitwise_and(frame_resized, frame_resized, mask=background_mask)\n",
    "\n",
    "    # Display the background alone \n",
    "    cv2.imshow('Background Only', background_mask)\n",
    "    # Display the foreground alone \n",
    "    cv2.imshow('Foreground Only', foreground_mask)\n",
    "    # Wait for any key press to exit\n",
    "    key = cv2.waitKey(30)\n",
    "    if key != -1:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334fea9-dae3-4dfb-8767-e12115cd402c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a38cc4-d4be-4305-bb05-44aeeb680cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78597a38-63f2-4f0d-8074-c71d6c6ca629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('Videos/Captures/duck.mp4')\n",
    "\n",
    "# Background subtractor with more sensitive parameters\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize the frame (50% of original size)\n",
    "    scale_percent = 50\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    frame_resized = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Apply background separation to detect motion\n",
    "    fgmask = fgbg.apply(frame_resized)\n",
    "    \n",
    "    # Threshold with a lower value to capture more motion\n",
    "    _, motion_mask = cv2.threshold(fgmask, 20, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Light noise reduction with a small kernel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    motion_mask_cleaned = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours, but lower the area threshold to keep more motion\n",
    "    contours, _ = cv2.findContours(motion_mask_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a blank mask for motion only\n",
    "    motion_only = np.zeros_like(motion_mask_cleaned)\n",
    "    \n",
    "    # Draw contours with a lower area threshold\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 50:  # Reduced from 100 to capture smaller motion\n",
    "            cv2.drawContours(motion_only, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    # Foreground: Apply motion mask to original frame\n",
    "    foreground = cv2.bitwise_and(frame_resized, frame_resized, mask=motion_only)\n",
    "    \n",
    "    # Background: Invert the motion mask and apply to original frame\n",
    "    background_mask = cv2.bitwise_not(motion_only)\n",
    "    background = cv2.bitwise_and(frame_resized, frame_resized, mask=background_mask)\n",
    "\n",
    "\n",
    "    \n",
    "    # Display the motion-only result (black and white)\n",
    "    cv2.imshow('Motion Only (Black and White)', motion_only)\n",
    "    \n",
    "    # Display the foreground (color)\n",
    "    cv2.imshow('Foreground', foreground)\n",
    "    \n",
    "    # Display the background (color)\n",
    "    cv2.imshow('Background', background)\n",
    "\n",
    "\n",
    "     # Create a copy of the frame to draw rectangles on\n",
    "    frame_with_rectangles = frame_resized.copy()\n",
    "    \n",
    "    # Draw rectangles around significant motion\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 200:  # Filter out small noise\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame_with_rectangles, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green rectangle\n",
    "    \n",
    "    # Display the frame with rectangles around motion\n",
    "    cv2.imshow('Motion with Rectangles', frame_with_rectangles)\n",
    "\n",
    "    \n",
    "    # Wait for any key press to exit\n",
    "    key = cv2.waitKey(30)\n",
    "    if key != -1:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "741f786b-1af4-4c1a-8a5a-673b61cbafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('Videos/Captures/indoorplay.mp4')\n",
    "\n",
    "# Background subtractor with balanced parameters\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(varThreshold=10, detectShadows=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize the frame (50% of original size)\n",
    "    scale_percent = 50\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    frame_resized = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Apply light Gaussian blur to reduce minor noise (e.g., court texture)\n",
    "    frame_blurred = cv2.GaussianBlur(frame_resized, (5, 5), 0)\n",
    "    \n",
    "    # Apply background separation to detect motion\n",
    "    fgmask = fgbg.apply(frame_blurred)\n",
    "    \n",
    "    # Threshold to capture player motion, less sensitive to court\n",
    "    _, motion_mask = cv2.threshold(fgmask, 25, 100, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Noise reduction with morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    motion_mask_cleaned = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel)  # Remove small noise\n",
    "    motion_mask_cleaned = cv2.morphologyEx(motion_mask_cleaned, cv2.MORPH_CLOSE, kernel)  # Fill player gaps\n",
    "    \n",
    "    # Contour filtering to isolate players, ignore court noise\n",
    "    contours, _ = cv2.findContours(motion_mask_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    motion_only = np.zeros_like(motion_mask_cleaned)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 200:  # Larger threshold to focus on players\n",
    "            cv2.drawContours(motion_only, [contour], -1, (250), thickness=cv2.FILLED)\n",
    "    \n",
    "    # Foreground: Apply motion mask to original frame (players alone)\n",
    "    foreground = cv2.bitwise_and(frame_resized, frame_resized, mask=motion_only)\n",
    "    \n",
    "    # Background: Invert the motion mask and apply to original frame\n",
    "    background_mask = cv2.bitwise_not(motion_only)\n",
    "    background = cv2.bitwise_and(frame_resized, frame_resized, mask=background_mask)\n",
    "    \n",
    "    # Display the motion-only result (black and white)\n",
    "    cv2.imshow('Motion Only (Black and White)', motion_only)\n",
    "    \n",
    "    # Display the foreground (players in color)\n",
    "    cv2.imshow('Foreground - Players', foreground)\n",
    "    \n",
    "    # Display the background (court without players)\n",
    "    cv2.imshow('Background', background)\n",
    "\n",
    "    \n",
    "        # Create a copy of the frame to draw rectangles on\n",
    "    frame_with_rectangles = frame_resized.copy()\n",
    "    \n",
    "    # Draw rectangles around significant motion\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 250:  # Filter out small noise\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame_with_rectangles, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green rectangle\n",
    "    \n",
    "    # Display the frame with rectangles around motion\n",
    "    cv2.imshow('Motion with Rectangles', frame_with_rectangles)\n",
    "    # Wait for any key press to exit\n",
    "    key = cv2.waitKey(30)\n",
    "    if key != -1:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b90960e-6974-4ae2-bf9e-2acff24d1560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene change at frame 1, motion area: 229401, diff: 229401\n",
      "Scene change at frame 2, motion area: 4069, diff: 225332\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_video(video_path, motion_threshold=250, diff_threshold=25):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Background subtractor\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=15, detectShadows=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    prev_motion_area = 0\n",
    "    scene_change_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "        # Resize frame (50% scale)\n",
    "        scale = 50\n",
    "        width, height = int(frame.shape[1] * scale / 100), int(frame.shape[0] * scale / 100)\n",
    "        frame_resized = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Noise reduction\n",
    "        frame_blurred = cv2.GaussianBlur(frame_resized, (7, 7), 1.5)\n",
    "        \n",
    "        # Background subtraction\n",
    "        fgmask = fgbg.apply(frame_blurred)\n",
    "        \n",
    "        # Thresholding\n",
    "        _, motion_mask = cv2.threshold(fgmask, 30, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Morphological operations\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "        motion_mask_cleaned = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "        motion_mask_cleaned = cv2.morphologyEx(motion_mask_cleaned, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        \n",
    "        # Contour detection\n",
    "        contours, _ = cv2.findContours(motion_mask_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        motion_area = sum(cv2.contourArea(c) for c in contours if cv2.contourArea(c) > motion_threshold)\n",
    "\n",
    "        # Scene change detection\n",
    "        area_diff = abs(motion_area - prev_motion_area)\n",
    "        frame_with_rect = frame_resized.copy()\n",
    "\n",
    "        # Draw rectangles on every frame\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > motion_threshold:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame_with_rect, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Highlight scene changes with text\n",
    "        if area_diff > diff_threshold * 1000:\n",
    "            scene_change_count += 1\n",
    "            cv2.putText(frame_with_rect, f\"Scene Change {scene_change_count}\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            print(f\"Scene change at frame {frame_count}, motion area: {motion_area:.0f}, diff: {area_diff:.0f}\")\n",
    "\n",
    "        # Display the processed frame\n",
    "        cv2.imshow('Processed Video', frame_with_rect)\n",
    "\n",
    "        # Exit on key press (e.g., 'q')\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        prev_motion_area = motion_area\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    video_path = \"Videos/Captures/indoorplay.mp4\"  # Input video\n",
    "    process_video(video_path, motion_threshold=300, diff_threshold=30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8730d5-5e9f-4392-969d-4d8423777af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9954607-8f2c-455f-a4c6-25af282f3ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
